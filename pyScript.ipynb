{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('expand_frame_repr',False)\n",
    "#import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the input file\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "train = cwd + \"\\\\Source\\\\train.csv\"\n",
    "train = pd.read_csv(train)\n",
    "\n",
    "test = cwd + \"\\\\Source\\\\test.csv\"\n",
    "test = pd.read_csv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train[train['Employment.Type'].notnull()]['loan_default'].value_counts() / len(train[train['Employment.Type'].notnull()]))\n",
    "# print(train[train['Employment.Type'].isnull()]['loan_default'].value_counts() / len(train[train['Employment.Type'].isnull()]))\n",
    "# print(train[train['Employment.Type']=='Self employed']['loan_default'].value_counts() / len(train[train['Employment.Type']=='Self employed']))\n",
    "# print(train[train['Employment.Type']=='Salaried']['loan_default'].value_counts() / len(train[train['Employment.Type']=='Salaried']))\n",
    "\n",
    "# # Though there are not much differences between the default distribution, it appears as if the Salaried people are more \n",
    "# # likely to pay loan in item when compared to Self Employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the date formats\n",
    "\n",
    "train['Date.of.Birth'] = pd.to_datetime(train['Date.of.Birth'], dayfirst=True)\n",
    "train['DisbursalDate'] = pd.to_datetime(train['DisbursalDate'], dayfirst=True)\n",
    "\n",
    "test['Date.of.Birth'] = pd.to_datetime(test['Date.of.Birth'], dayfirst=True)\n",
    "test['DisbursalDate'] = pd.to_datetime(test['DisbursalDate'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating backup of the data\n",
    "\n",
    "train_backup = train.copy()\n",
    "test_backup = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Restoring backup\n",
    "\n",
    "# train = train_backup.copy()\n",
    "# test = test_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default = train[(train.loan_default==1) & (train['PERFORM_CNS.SCORE']<100)]\n",
    "# no_default = train[(train.loan_default==0) & (train['PERFORM_CNS.SCORE']<100)]\n",
    "\n",
    "#default.describe()\n",
    "#print(no_default.describe)\n",
    "#sample[(sample['PERFORM_CNS.SCORE']>600) & (sample['PERFORM_CNS.SCORE']<700)].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Creating the age of loan applicant at the time of disbursal\n",
    "train['Age_when_applying'] = (train['DisbursalDate'] - train['Date.of.Birth']).dt.days / 365\n",
    "test['Age_when_applying'] = (train['DisbursalDate'] - test['Date.of.Birth']).dt.days / 365\n",
    "train['Age_when_applying'] = np.where(train['Age_when_applying'] < 0, 100+train['Age_when_applying'], train['Age_when_applying'])\n",
    "test['Age_when_applying'] = np.where(test['Age_when_applying'] < 0, 100+test['Age_when_applying'], test['Age_when_applying'])\n",
    "\n",
    "# Creating the avg acct age and cred hist age in months\n",
    "train['avg_acct_age_mnth'] = ((train['AVERAGE.ACCT.AGE'].str.extract('(\\d+)yrs').astype('int64')*12) + train['AVERAGE.ACCT.AGE'].str.extract('(\\d+)mon').astype('int64'))\n",
    "train['avg_credit_hist_mnth'] = ((train['CREDIT.HISTORY.LENGTH'].str.extract('(\\d+)yrs').astype('int64')*12) + train['CREDIT.HISTORY.LENGTH'].str.extract('(\\d+)mon').astype('int64'))\n",
    "\n",
    "test['avg_acct_age_mnth'] = ((test['AVERAGE.ACCT.AGE'].str.extract('(\\d+)yrs').astype('int64')*12) + test['AVERAGE.ACCT.AGE'].str.extract('(\\d+)mon').astype('int64'))\n",
    "test['avg_credit_hist_mnth'] = ((test['CREDIT.HISTORY.LENGTH'].str.extract('(\\d+)yrs').astype('int64')*12) + test['CREDIT.HISTORY.LENGTH'].str.extract('(\\d+)mon').astype('int64'))\n",
    "\n",
    "# Creating a Overdue Percentage for Primary and Seconardy Accounts\n",
    "\n",
    "train['prim_overdue_acct_pct'] = (train['PRI.OVERDUE.ACCTS'] / train['PRI.NO.OF.ACCTS']).fillna(0)\n",
    "train['sec_overdue_acct_pct'] = (train['SEC.OVERDUE.ACCTS'] / train['SEC.NO.OF.ACCTS']).fillna(0)\n",
    "\n",
    "test['prim_overdue_acct_pct'] = (test['PRI.OVERDUE.ACCTS'] / test['PRI.NO.OF.ACCTS']).fillna(0)\n",
    "test['sec_overdue_acct_pct'] = (test['SEC.OVERDUE.ACCTS'] / test['SEC.NO.OF.ACCTS']).fillna(0)\n",
    "\n",
    "# Creating loan to asset ratio\n",
    "train['asset_to_loan_pct'] =  train['asset_cost'] / train['disbursed_amount']\n",
    "test['asset_to_loan_pct'] =  test['asset_cost'] / test['disbursed_amount']\n",
    "\n",
    "# Imputing zero values of CNS Score (Test data also imputed with train mean)\n",
    "cred_score_value = np.quantile(train['PERFORM_CNS.SCORE'][train['PERFORM_CNS.SCORE'] > 100], 0.25)\n",
    "train['credit_score'] = np.where(train['PERFORM_CNS.SCORE'] < 100, cred_score_value, train['PERFORM_CNS.SCORE'])\n",
    "test['credit_score'] = np.where(test['PERFORM_CNS.SCORE'] < 100, cred_score_value, test['PERFORM_CNS.SCORE'])\n",
    "\n",
    "# Credit History Desc\n",
    "train['credit_score_desc'] = np.where(train.credit_score < 450, 'High Risk', \n",
    "                                             np.where(train.credit_score < 800, 'Medium Risk', 'Low Risk'))\n",
    "\n",
    "test['credit_score_desc'] = np.where(test['credit_score'] < 450, 'High Risk',\n",
    "                                              np.where(test['credit_score'] < 800, 'Medium Risk', 'Low Risk'))\n",
    "train.loc[train.credit_score == 300, 'credit_score_desc'] = 'Medium Risk'\n",
    "test.loc[test.credit_score == 300, 'credit_score_desc'] = 'Medium Risk'\n",
    "\n",
    "# Creating a Total Outstanding balance\n",
    "train['total_outstanding'] = train['disbursed_amount'] + train['PRI.CURRENT.BALANCE']\n",
    "test['total_outstanding'] = test['disbursed_amount'] + test['PRI.CURRENT.BALANCE']\n",
    "\n",
    "# Current to Outstanding ratio\n",
    "train['curr_outstd_ratio'] = train['disbursed_amount'] / (train['disbursed_amount'] + train['PRI.CURRENT.BALANCE'])\n",
    "test['curr_outstd_ratio'] = test['disbursed_amount'] / (test['disbursed_amount'] + test['PRI.CURRENT.BALANCE'])\n",
    "\n",
    "# Previous Installment Capability\n",
    "train['instalment_health'] = train['PRI.DISBURSED.AMOUNT'] / train['avg_credit_hist_mnth']\n",
    "test['instalment_health'] = test['PRI.DISBURSED.AMOUNT'] / test['avg_credit_hist_mnth']\n",
    "\n",
    "\n",
    "# Previous Installment to Current Disbursed Amt Ratio\n",
    "\n",
    "train['inst_curr_disb_ratio'] = train['instalment_health'] / train['disbursed_amount']\n",
    "test['inst_curr_disb_ratio'] = test['instalment_health'] / test['disbursed_amount']\n",
    "\n",
    "# Filling missing values and inf values for Instalment Health and instalment to current disbursed ratio\n",
    "train['instalment_health'].fillna(-9999, inplace=True)\n",
    "test['instalment_health'].fillna(-9999, inplace=True)\n",
    "train['inst_curr_disb_ratio'].fillna(-9.9, inplace=True)\n",
    "test['inst_curr_disb_ratio'].fillna(-9.9, inplace=True)\n",
    "\n",
    "train['instalment_health'] = np.where(np.isinf(train['instalment_health']),-999, train['instalment_health'])\n",
    "test['instalment_health'] = np.where(np.isinf(test['instalment_health']),-999, test['instalment_health'])\n",
    "train['inst_curr_disb_ratio'] = np.where(np.isinf(train['inst_curr_disb_ratio']),-0.9, train['inst_curr_disb_ratio'])\n",
    "test['inst_curr_disb_ratio'] = np.where(np.isinf(test['inst_curr_disb_ratio']),-0.9, test['inst_curr_disb_ratio'])\n",
    "\n",
    "\n",
    "# Impute Missing Employment Type with Unemployed\n",
    "train['Employment.Type'] = np.where(train['Employment.Type'].isnull(), 'Unemployed', train['Employment.Type'])\n",
    "test['Employment.Type'] = np.where(test['Employment.Type'].isnull(), 'Unemployed', test['Employment.Type'])\n",
    "\n",
    "\n",
    "# Creating Age to Total Outstanding Ratio\n",
    "train['age_outstd_ratio'] = train['Age_when_applying'] / train['total_outstanding']\n",
    "test['age_outstd_ratio'] = test['Age_when_applying'] / test['total_outstanding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating additional features\n",
    "\n",
    "# For State_ID\n",
    "\n",
    "count = train.State_ID.value_counts().reset_index()\n",
    "count.columns = ['State_ID', 'count']\n",
    "\n",
    "default_count = train.State_ID[train.loan_default==1].value_counts().reset_index()\n",
    "default_count.columns = ['State_ID', 'default_count']\n",
    "\n",
    "df = pd.merge(count, default_count, how='left', on='State_ID')\n",
    "df['def_pct_by_state'] = np.round(df.default_count / df['count'],2)\n",
    "df['def_pct_by_state'].fillna(0, inplace=True)\n",
    "\n",
    "train = pd.merge(train, df.iloc[:,[0,3]], how='left', on='State_ID')\n",
    "test = pd.merge(test, df.iloc[:,[0,3]], how='left', on='State_ID')\n",
    "\n",
    "# For supplier_id\n",
    "\n",
    "count = train.supplier_id.value_counts().reset_index()\n",
    "count.columns = ['supplier_id', 'count']\n",
    "\n",
    "default_count = train.supplier_id[train.loan_default==1].value_counts().reset_index()\n",
    "default_count.columns = ['supplier_id', 'default_count']\n",
    "\n",
    "df = pd.merge(count, default_count, how='left', on='supplier_id')\n",
    "df['def_pct_by_supplier'] = np.round(df.default_count / df['count'],2)\n",
    "df['def_pct_by_supplier'].fillna(0, inplace=True)\n",
    "\n",
    "train = pd.merge(train, df.iloc[:,[0,3]], how='left', on='supplier_id')\n",
    "test = pd.merge(test, df.iloc[:,[0,3]], how='left', on='supplier_id')\n",
    "\n",
    "# For branch_id\n",
    "\n",
    "count = train.branch_id.value_counts().reset_index()\n",
    "count.columns = ['branch_id', 'count']\n",
    "\n",
    "default_count = train.branch_id[train.loan_default==1].value_counts().reset_index()\n",
    "default_count.columns = ['branch_id', 'default_count']\n",
    "\n",
    "df = pd.merge(count, default_count, how='left', on='branch_id')\n",
    "df['def_pct_by_branch'] = np.round(df.default_count / df['count'],2)\n",
    "df['def_pct_by_branch'].fillna(0, inplace=True)\n",
    "\n",
    "train = pd.merge(train, df.iloc[:,[0,3]], how='left', on='branch_id')\n",
    "test = pd.merge(test, df.iloc[:,[0,3]], how='left', on='branch_id')\n",
    "\n",
    "# For manufacturer_id\n",
    "\n",
    "count = train.manufacturer_id.value_counts().reset_index()\n",
    "count.columns = ['manufacturer_id', 'count']\n",
    "\n",
    "default_count = train.manufacturer_id[train.loan_default==1].value_counts().reset_index()\n",
    "default_count.columns = ['manufacturer_id', 'default_count']\n",
    "\n",
    "df = pd.merge(count, default_count, how='left', on='manufacturer_id')\n",
    "df['def_pct_by_manufacturer'] = np.round(df.default_count / df['count'],2)\n",
    "df['def_pct_by_manufacturer'].fillna(0, inplace=True)\n",
    "\n",
    "train = pd.merge(train, df.iloc[:,[0,3]], how='left', on='manufacturer_id')\n",
    "test = pd.merge(test, df.iloc[:,[0,3]], how='left', on='manufacturer_id')\n",
    "\n",
    "# For Employee_code_ID\n",
    "\n",
    "count = train.Employee_code_ID.value_counts().reset_index()\n",
    "count.columns = ['Employee_code_ID', 'count']\n",
    "\n",
    "default_count = train.Employee_code_ID[train.loan_default==1].value_counts().reset_index()\n",
    "default_count.columns = ['Employee_code_ID', 'default_count']\n",
    "\n",
    "df = pd.merge(count, default_count, how='left', on='Employee_code_ID')\n",
    "df['def_pct_by_emp'] = np.round(df.default_count / df['count'],2)\n",
    "df['def_pct_by_emp'].fillna(0, inplace=True)\n",
    "\n",
    "train = pd.merge(train, df.iloc[:,[0,3]], how='left', on='Employee_code_ID')\n",
    "test = pd.merge(test, df.iloc[:,[0,3]], how='left', on='Employee_code_ID')\n",
    "\n",
    "# For Current_pincode_ID\n",
    "\n",
    "count = train.Current_pincode_ID.value_counts().reset_index()\n",
    "count.columns = ['Current_pincode_ID', 'count']\n",
    "\n",
    "default_count = train.Current_pincode_ID[train.loan_default==1].value_counts().reset_index()\n",
    "default_count.columns = ['Current_pincode_ID', 'default_count']\n",
    "\n",
    "df = pd.merge(count, default_count, how='left', on='Current_pincode_ID')\n",
    "df['def_pct_by_pin'] = np.round(df.default_count / df['count'],2)\n",
    "df['def_pct_by_pin'].fillna(0, inplace=True)\n",
    "\n",
    "train = pd.merge(train, df.iloc[:,[0,3]], how='left', on='Current_pincode_ID')\n",
    "test = pd.merge(test, df.iloc[:,[0,3]], how='left', on='Current_pincode_ID')\n",
    "\n",
    "test.fillna(test.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns for predictors:\n",
    "\n",
    "predictors = ['disbursed_amount', 'asset_cost', 'ltv','MobileNo_Avl_Flag', 'Aadhar_flag', 'PAN_flag', 'VoterID_flag', 'Driving_flag', 'Passport_flag', 'PERFORM_CNS.SCORE',\n",
    "       'PRI.NO.OF.ACCTS', 'PRI.ACTIVE.ACCTS', 'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE', 'PRI.SANCTIONED.AMOUNT', 'PRI.DISBURSED.AMOUNT',\n",
    "       'SEC.NO.OF.ACCTS', 'SEC.ACTIVE.ACCTS', 'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE', 'SEC.SANCTIONED.AMOUNT', 'SEC.DISBURSED.AMOUNT',\n",
    "       'PRIMARY.INSTAL.AMT', 'SEC.INSTAL.AMT', 'NEW.ACCTS.IN.LAST.SIX.MONTHS', 'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', 'NO.OF_INQUIRIES', 'avg_acct_age_mnth', 'avg_credit_hist_mnth',\n",
    "       'Age_when_applying', 'prim_overdue_acct_pct', 'sec_overdue_acct_pct', 'asset_to_loan_pct']\n",
    "\n",
    "# Predictors for Random Forest Classifer after optimizing for Feature Importance\n",
    "predictors = ['disbursed_amount', 'asset_cost', 'ltv','Aadhar_flag', 'PAN_flag', 'VoterID_flag', 'Driving_flag', 'credit_score',\n",
    "              'PRI.NO.OF.ACCTS', 'PRI.ACTIVE.ACCTS', 'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE', 'PRI.SANCTIONED.AMOUNT', \n",
    "              'PRI.DISBURSED.AMOUNT', 'PRIMARY.INSTAL.AMT', 'NEW.ACCTS.IN.LAST.SIX.MONTHS', \n",
    "              'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', 'NO.OF_INQUIRIES', 'avg_acct_age_mnth', 'avg_credit_hist_mnth', \n",
    "              'Age_when_applying', 'prim_overdue_acct_pct','asset_to_loan_pct', 'credit_score_desc', 'Employment.Type', \n",
    "              'inst_curr_disb_ratio', 'instalment_health', 'curr_outstd_ratio', 'total_outstanding', 'age_outstd_ratio',\n",
    "             'def_pct_by_pin', 'def_pct_by_emp', 'def_pct_by_manufacturer', 'def_pct_by_state', 'def_pct_by_supplier', \n",
    "             'def_pct_by_branch']\n",
    "\n",
    "# Predictors for Random Forest Classifer after 0.63 Score\n",
    "# predictors = ['disbursed_amount', 'asset_cost', 'ltv', 'credit_score',\n",
    "#               'PRI.NO.OF.ACCTS', 'PRI.ACTIVE.ACCTS', 'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE', 'PRI.SANCTIONED.AMOUNT', \n",
    "#               'PRI.DISBURSED.AMOUNT', 'PRIMARY.INSTAL.AMT', 'NEW.ACCTS.IN.LAST.SIX.MONTHS', \n",
    "#               'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', 'NO.OF_INQUIRIES', 'avg_acct_age_mnth', 'avg_credit_hist_mnth', \n",
    "#               'Age_when_applying', 'prim_overdue_acct_pct','asset_to_loan_pct', \n",
    "#               'inst_curr_disb_ratio', 'instalment_health', 'curr_outstd_ratio', 'total_outstanding', 'age_outstd_ratio',\n",
    "#              'def_pct_by_pin', 'def_pct_by_emp', 'def_pct_by_manufacturer', 'def_pct_by_state', 'def_pct_by_supplier', \n",
    "#              'def_pct_by_branch']\n",
    "\n",
    "target = 'loan_default'\n",
    "x = train[predictors]\n",
    "y = train[target]\n",
    "test_data = test[predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dummy Data\n",
    "\n",
    "x = pd.get_dummies(x)\n",
    "test_data = pd.get_dummies(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardizing the data to perform naive bayes\n",
    "\n",
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# transform_data = QuantileTransformer(output_distribution='normal')\n",
    "# col_names = x.columns\n",
    "\n",
    "# x = transform_data.fit_transform(x)\n",
    "# x = pd.DataFrame(data=x, columns=col_names)\n",
    "\n",
    "# test_data = transform_data.fit_transform(test_data)\n",
    "# test_data = pd.DataFrame(data=test_data, columns=col_names)\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# transform_data = StandardScaler()\n",
    "# col_names = x.columns\n",
    "\n",
    "# x = transform_data.fit_transform(x)\n",
    "# x = pd.DataFrame(data=x, columns=col_names)\n",
    "\n",
    "# test_data = transform_data.fit_transform(test_data)\n",
    "# test_data = pd.DataFrame(data=test_data, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colNames = x_train.columns\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=200)\n",
    "# x_train = pca.fit_transform(x_train)\n",
    "# pca_colNames = colNames[0:200]\n",
    "\n",
    "# x_train = pd.DataFrame(data=x_train, columns=pca_colNames)\n",
    "\n",
    "# np.sum(pca.explained_variance_ratio_)\n",
    "\n",
    "# x_validation = pca.fit_transform(x_validation)\n",
    "# x_validation = pd.DataFrame(data=x_validation, columns=pca_colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x,y, stratify=y, random_state=1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNDER SAMPLING DATA\n",
    "sampleData = x_train.copy()\n",
    "sampleData['target'] = y_train\n",
    "\n",
    "underSample_length = len(sampleData[sampleData.target == 1])\n",
    "\n",
    "zero_target_indices = sampleData[sampleData.target == 0].index\n",
    "random_indices = np.random.choice(zero_target_indices, underSample_length, replace=False)\n",
    "\n",
    "target_data = sampleData[sampleData.target == 1]\n",
    "zero_target_data = sampleData[sampleData.index.isin(random_indices)]\n",
    "x_train = pd.concat([target_data, zero_target_data])\n",
    "\n",
    "y_train = x_train['target']\n",
    "x_train = x_train.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Running a Naive Bayes Model\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# model = GaussianNB()\n",
    "\n",
    "# # Training the model\n",
    "\n",
    "# model.fit(x_train, y_train)\n",
    "# train_predictions = model.predict(x_train)\n",
    "# predictions = model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Converting to lgbm dataset\n",
    "\n",
    "# import lightgbm as lgb\n",
    "\n",
    "# x_train = lgb.Dataset(x_train, free_raw_data=False)\n",
    "# x_validation = lgb.Dataset(x_validation, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Running LGBM\n",
    "\n",
    "# # Setting Parameters:\n",
    "\n",
    "# param = {\n",
    "#         'num_leaves': 4,\n",
    "#         'objective': 'binary',\n",
    "#         'metric': 'auc',\n",
    "#         'early_stopping_rounds':10,\n",
    "#        }\n",
    "\n",
    "# num_round=10\n",
    "# model = lgb.train(param, x_train, num_round, valid_sets=[x_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Running a Random Forest Classifier\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# #model = RandomForestClassifier(n_estimators=100, criterion='gini', min_samples_split=10, min_samples_leaf=3, bootstrap=True, oob_score=True, n_jobs=-1, random_state=10)\n",
    "# # model = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=25, min_samples_leaf=5, oob_score=True, n_jobs=-1, random_state=10)\n",
    "\n",
    "# model = RandomForestClassifier(n_estimators=450, min_samples_split=10,min_samples_leaf=4, max_features=7, max_depth = 15, criterion='gini', bootstrap=False)\n",
    "# # Training the model\n",
    "\n",
    "# model.fit(x_train, y_train)\n",
    "# train_predictions = model.predict(x_train)\n",
    "# predictions = model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Importance Graph\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# feat_importances = pd.Series(model.feature_importances_, index=x_train.columns)\n",
    "# feat_importances.nlargest(105).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confusion Matrix and Report\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Confusion Matrix Comparison\n",
    "# print(\"Confustion Matrix for Training Data\")\n",
    "# print(confusion_matrix(y_train, train_predictions))\n",
    "# print(\"Confustion Matrix for Test Data\")\n",
    "# print(confusion_matrix(y_validation, predictions))\n",
    "\n",
    "# # Classification Report Comparison\n",
    "# print(\"Classification Report for Training Data\")\n",
    "# print(classification_report(y_train, train_predictions))\n",
    "# print(\"Classification Report for Test Data\")\n",
    "# print(classification_report(y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AUC ROC CURVE\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import roc_curve\n",
    "\n",
    "# predictions = model.predict_proba(x_validation)[:,1]\n",
    "# roc_auc_score(y_validation, predictions, average='weighted')\n",
    "\n",
    "# fpr, tpr, threshold = roc_curve(y_validation, predictions)\n",
    "\n",
    "# # Calculating the AUC Score\n",
    "# auc = np.trapz(tpr,fpr)\n",
    "# pltTitle = print(\"AUROC Plot:\", \"%.4f\" %auc)\n",
    "\n",
    "# # Plotting the ROC Curve\n",
    "# plt.plot(fpr,tpr)\n",
    "# plt.title(pltTitle)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Applying Model for Test Data\n",
    "\n",
    "# predictions = model.predict_proba(test_data)[:,1]\n",
    "# id_code = test['UniqueID']\n",
    "\n",
    "# output = pd.DataFrame({'UniqueID': id_code, 'loan_default':predictions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.to_csv(cwd + \"\\\\Output\\\\Submission 9 - RF RANDOM SEARCH ALTERNATE 3 MODEL WITH LESS FEATURES 0.71 AUC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM SEARCH OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a Random Grid\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from pprint import pprint\n",
    "# # model = (n_estimators=500, criterion='gini', max_depth=25, min_samples_leaf=5, oob_score=True, n_jobs=-1, random_state=10)\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start=50, stop=500, num=10)]\n",
    "\n",
    "# # Number of features to consider at every split (For max_features we can also consider sqrt or auto)\n",
    "# max_features = [int(x) for x in np.linspace(start= np.int(len(x_train.columns)/10),\n",
    "#                                             stop= np.int(len(x_train.columns)/2), num=5)]\n",
    "# # The split criterion\n",
    "# criterion = ['gini', 'entropy']\n",
    "\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(5, 25, num = 5)]\n",
    "\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'criterion': criterion,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Performing the Random Search\n",
    "\n",
    "# # Use the random grid to search for best hyperparameters\n",
    "# # Let us use the base model \"model\" that is already created to tune the model against\n",
    "# model = RandomForestClassifier()\n",
    "# # Random search of parameters, using 5 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# model_random = RandomizedSearchCV(estimator = model, \n",
    "#                                   param_distributions = random_grid, \n",
    "#                                   n_iter = 20, cv = 3, verbose=250, random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# model_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the best parameters from the Random Search\n",
    "\n",
    "# model_random.best_params_\n",
    "\n",
    "# Below is the best parameter after tuning\n",
    "# (n_estimators=300, min_samples_split=10,min_samples_leaf=2, max_features=11, max_depth = 15, criterion='entropy', bootstrap=True  )\n",
    "\n",
    "# Below are alternative models with high score\n",
    "# ALT MODEL 1\n",
    "# (n_estimators=500, min_samples_split=5,min_samples_leaf=2, max_features=15, max_depth = 10, criterion='gini', bootstrap=True  )\n",
    "\n",
    "# ALT MODEL 2\n",
    "# (n_estimators=50, min_samples_split=10,min_samples_leaf=2, max_features=19, max_depth = 10, criterion='gini', bootstrap=True  )\n",
    "\n",
    "# ALT MODEL 3\n",
    "# (n_estimators=450, min_samples_split=10,min_samples_leaf=4, max_features=7, max_depth = 15, criterion='gini', bootstrap=False  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Matrix for Training Data\n",
      "[[30195  7763]\n",
      " [ 5531 32427]]\n",
      "Confustion Matrix for Test Data\n",
      "[[28697 16939]\n",
      " [ 4108  8545]]\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82     37958\n",
      "           1       0.81      0.85      0.83     37958\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     75916\n",
      "   macro avg       0.83      0.82      0.82     75916\n",
      "weighted avg       0.83      0.82      0.82     75916\n",
      "\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.63      0.73     45636\n",
      "           1       0.34      0.68      0.45     12653\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     58289\n",
      "   macro avg       0.61      0.65      0.59     58289\n",
      "weighted avg       0.76      0.64      0.67     58289\n",
      "\n",
      "AUROC Plot: 0.7112\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=450, min_samples_split=10,min_samples_leaf=4, max_features=7, max_depth = 15,\n",
    "                               criterion='gini', bootstrap=False, n_jobs=-1, random_state=10, class_weight='balanced')\n",
    "\n",
    "# Training the model\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "train_predictions = model.predict(x_train)\n",
    "predictions = model.predict(x_validation)\n",
    "\n",
    "# Confusion Matrix and Report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Confusion Matrix Comparison\n",
    "print(\"Confustion Matrix for Training Data\")\n",
    "print(confusion_matrix(y_train, train_predictions))\n",
    "print(\"Confustion Matrix for Test Data\")\n",
    "print(confusion_matrix(y_validation, predictions))\n",
    "\n",
    "# Classification Report Comparison\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_validation, predictions))\n",
    "\n",
    "# AUC ROC CURVE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "predictions = model.predict_proba(x_validation)[:,1]\n",
    "roc_auc_score(y_validation, predictions, average='weighted')\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_validation, predictions)\n",
    "\n",
    "# Calculating the AUC Score\n",
    "auc = np.trapz(tpr,fpr)\n",
    "print(\"AUROC Plot:\", \"%.4f\" %auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Model for Test Data\n",
    "\n",
    "predictions = model.predict_proba(test_data)[:,1]\n",
    "id_code = test['UniqueID']\n",
    "\n",
    "output = pd.DataFrame({'UniqueID': id_code, 'loan_default':predictions})\n",
    "output.to_csv(cwd + \"\\\\Output\\\\Final Submission - RF RANDOM SEARCH ALTERNATE 3 MODEL WITH ADDED FEATURES 0.7111 AUC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM OPTIMIZER FOR XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a Random Grid\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from pprint import pprint\n",
    "\n",
    "# # Minimum Child Weight\n",
    "# min_child_weight = [int(x) for x in np.linspace(start=0, stop=6, num=7)]\n",
    "\n",
    "# # Tuning for gamma\n",
    "# gamma = [i/10.0 for i in range(0,5)]\n",
    "\n",
    "# # Tuning regularization parameter\n",
    "# reg_alpha = [1e-5, 1e-2, 0.1, 1]\n",
    "\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(3, 6, num = 4)]\n",
    "\n",
    "# # Learning Rate\n",
    "# learning_rate = [0.01, 0.02, 0.03, 0.07, 0.1, 0.3, 0.5]\n",
    "\n",
    "# n_estimators=[100, 300, 500, 800, 1000]\n",
    "\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_child_weight': min_child_weight,\n",
    "#                'gamma': gamma,\n",
    "#                'reg_alpha': reg_alpha,\n",
    "#                'learning_rate': learning_rate}\n",
    "\n",
    "# pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Performing the Random Search\n",
    "# from xgboost import XGBClassifier\n",
    "# # Use the random grid to search for best hyperparameters\n",
    "# # Let us use the base model \"model\" that is already created to tune the model against\n",
    "# model = XGBClassifier()\n",
    "# # Random search of parameters, using 5 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# model_random = RandomizedSearchCV(estimator = model, \n",
    "#                                   param_distributions = random_grid, \n",
    "#                                   n_iter = 50, cv = 4, verbose=10, random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# model_random.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best params for model with the entire data\n",
    "\n",
    "# model_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {'reg_alpha': 0.01,\n",
    "# #  'n_estimators': 300,\n",
    "# #  'min_child_weight': 5,\n",
    "# #  'max_depth': 3,\n",
    "# #  'learning_rate': 0.1,\n",
    "# #  'gamma': 0.1}\n",
    "\n",
    "# # Top 5 Models:\n",
    "# # (reg_alpha=0.01, n_estimators=300, min_child_weight=5, max_depth=3, learning_rate=0.1, gamma=0.1) 0.6582\n",
    "# # (reg_alpha=1, n_estimators=500, min_child_weight=6, max_depth=4, learning_rate=0.03, gamma=0.1)  0.6580 \n",
    "# # (reg_alpha=0.01, n_estimators=300, min_child_weight=2, max_depth=6, learning_rate=0.03, gamma=0.0)  0.6578\n",
    "# # (reg_alpha=0.01, n_estimators=300, min_child_weight=0, max_depth=3, learning_rate=0.07, gamma=0.0)  0.6573\n",
    "# # (reg_alpha=0.01, n_estimators=500, min_child_weight=3, max_depth=4, learning_rate=0.02, gamma=0.0)  0.6572\n",
    "# # (reg_alpha=1, n_estimators=500, min_child_weight=0, max_depth=3, learning_rate=0.03, gamma=0.1)  0.6571\n",
    "\n",
    "# # Top 5 Models using all data\n",
    "# # (reg_alpha=0.01, n_estimators=800, min_child_weight=1, max_depth=3, learning_rate=0.02, gamma=0.2) 0.788753399\n",
    "# # (reg_alpha=1, n_estimators=500, min_child_weight=0, max_depth=3, learning_rate=0.03, gamma=0.1) 0.788620439\n",
    "# # (reg_alpha=1, n_estimators=500, min_child_weight=6, max_depth=4, learning_rate=0.03, gamma=0.1) 0.788603281\n",
    "# # (reg_alpha=0.01, n_estimators=500, min_child_weight=3, max_depth=4, learning_rate=0.02, gamma=0.0) 0.788598999\n",
    "# # (reg_alpha=0.01, n_estimators=300, min_child_weight=0, max_depth=3, learning_rate=0.07, gamma=0.0) 0.788590411\n",
    "\n",
    "\n",
    "\n",
    "# # Running the customized parameter (took the best numbers for each parameter from the result)\n",
    "# model = XGBClassifier(reg_alpha=0.01, n_estimators=300, min_child_weight=0, max_depth=4, learning_rate=0.03, gamma=0.1)\n",
    "\n",
    "# model.fit(x_train, y_train)\n",
    "# train_predictions = model.predict(x_train)\n",
    "# predictions = model.predict(x_validation)\n",
    "\n",
    "# # Confusion Matrix and Report\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Confusion Matrix Comparison\n",
    "# print(\"Confustion Matrix for Training Data\")\n",
    "# print(confusion_matrix(y_train, train_predictions))\n",
    "# print(\"Confustion Matrix for Test Data\")\n",
    "# print(confusion_matrix(y_validation, predictions))\n",
    "\n",
    "# # Classification Report Comparison\n",
    "# print(\"Classification Report for Training Data\")\n",
    "# print(classification_report(y_train, train_predictions))\n",
    "# print(\"Classification Report for Test Data\")\n",
    "# print(classification_report(y_validation, predictions))\n",
    "\n",
    "# # AUC ROC CURVE\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import roc_curve\n",
    "\n",
    "# predictions = model.predict_proba(x_validation)[:,1]\n",
    "# roc_auc_score(y_validation, predictions, average='weighted')\n",
    "\n",
    "# fpr, tpr, threshold = roc_curve(y_validation, predictions)\n",
    "\n",
    "# # Calculating the AUC Score\n",
    "# auc = np.trapz(tpr,fpr)\n",
    "# print(\"AUROC Plot:\", \"%.4f\" %auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Applying Model for Test Data\n",
    "\n",
    "# predictions = model.predict_proba(test_data)[:,1]\n",
    "# id_code = test['UniqueID']\n",
    "\n",
    "# output = pd.DataFrame({'UniqueID': id_code, 'loan_default':predictions})\n",
    "# output.to_csv(cwd + \"\\\\Output\\\\Submission 15 - XGBoost Custom Best Model All Data 0.7167 AUC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import tools needed for visualization\n",
    "# from sklearn.tree import export_graphviz\n",
    "# import pydot\n",
    "\n",
    "# # Pull out one tree from the forest\n",
    "# tree = model.estimators_[5]\n",
    "\n",
    "# # Export the image to a dot file\n",
    "# export_graphviz(tree, out_file = 'tree.dot', feature_names = x_train.columns, rounded = True, precision = 1)\n",
    "\n",
    "# # Use dot file to create a graph\n",
    "# (graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "\n",
    "# # Write graph to a png file\n",
    "# graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization Reference\n",
    "# https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV\n",
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "# https://www.mathworks.com/help/stats/tune-random-forest-using-quantile-error-and-bayesian-optimization.html\n",
    "# https://www.kaggle.com/willkoehrsen/visualize-a-decision-tree-w-python-scikit-learn\n",
    "# https://towardsdatascience.com/running-random-forests-inspect-the-feature-importances-with-this-code-2b00dd72b92e\n",
    "# https://www.kaggle.com/residentmario/welcome-to-data-visualization\n",
    "# https://towardsdatascience.com/random-forest-in-python-24d0893d51c0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
